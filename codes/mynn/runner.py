import pickle
import numpy as np
import os
from tqdm import tqdm
import time

class RunnerM():

    def __init__(self, model, optimizer, metric, loss_fn, batch_size=32, scheduler=None):
        self.model = model
        self.optimizer = optimizer
        self.loss_fn = loss_fn
        self.metric = metric
        self.scheduler = scheduler
        self.batch_size = batch_size

        # è®­ç»ƒè®°å½•
        self.train_scores = []
        self.dev_scores = []
        self.train_loss = []
        self.dev_loss = []
        self.best_score = 0


    def train(self, train_set, dev_set, **kwargs):
        # å‚æ•°è®¾ç½®
        num_epochs = kwargs.get("num_epochs", 5)
        eval_interval = kwargs.get("eval_interval", 1000)  # è¯„ä¼°é—´éš”
        save_dir = kwargs.get("save_dir", "best_model")

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)

        # è®­ç»ƒå¾ªç¯
        for epoch in range(num_epochs):
            X, y = train_set
            X, y = self._shuffle_data(X, y)

            # ä½¿ç”¨tqdmè¿›åº¦æ¡
            num_batches = int(np.ceil(len(X) / self.batch_size))
            pbar = tqdm(range(num_batches), desc=f'Epoch {epoch + 1}/{num_epochs}')

            for iteration in pbar:
                # è·å–å½“å‰æ‰¹æ¬¡
                batch_X, batch_y = self._get_batch(X, y, iteration)
                # å‰å‘ä¼ æ’­
                logits = self.model(batch_X)

                trn_loss = self.loss_fn(logits, batch_y)
                trn_score = self.metric(logits, batch_y)

                # è®°å½•è®­ç»ƒæŒ‡æ ‡
                self.train_loss.append(trn_loss)
                self.train_scores.append(trn_score)

                # åœ¨è¿›åº¦æ¡æ˜¾ç¤ºå½“å‰è®­ç»ƒæŒ‡æ ‡
                pbar.set_postfix({
                    'train_loss': f'{trn_loss:.4f}',
                    'train_acc': f'{trn_score:.4f}'
                })

                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                self.loss_fn.backward()

                self.optimizer.step()
                if self.scheduler:
                    self.scheduler.step()

                # æ¯eval_intervalæ¬¡è¿­ä»£è¯„ä¼°ä¸€æ¬¡éªŒè¯é›†
                if (iteration + 1) % eval_interval == 0 or iteration == num_batches - 1:
                    dev_score, dev_loss = self.evaluate(dev_set)
                    self.dev_scores.append(dev_score)
                    self.dev_loss.append(dev_loss)

                    # æ›´æ–°æœ€ä½³æ¨¡å‹
                    if dev_score > self.best_score:
                        self.model.save_model(os.path.join(save_dir, 'best_model_CNN4visual.pickle'))
                        self.best_score = dev_score
                        pbar.write(f'ğŸŒŸ New best accuracy: {self.best_score:.4f}')

        print(f"Training complete! Best Dev Accuracy: {self.best_score:.4f}")


    def evaluate(self, data_set, batch_size=None):
        """æ‰¹é‡è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œä»…ä½¿ç”¨numpyåº“ï¼Œå¹¶è¾“å‡ºæ¯ä¸ªé˜¶æ®µçš„æ—¶é—´"""
        X, y = data_set


        # ç¡®ä¿Xå’Œyæ˜¯numpyæ•°ç»„
        X = np.array(X)
        y = np.array(y)

        # æµ‹é‡æ¨¡å‹æ¨ç†æ—¶é—´

        logits = self.model(X)

        # æµ‹é‡æŸå¤±è®¡ç®—æ—¶é—´

        total_loss = self.loss_fn(logits, y)

        total_score = self.metric(logits, y)


        # è®¡ç®—å¹³å‡æŸå¤±å’Œå¾—åˆ†
        return total_score,total_loss


    def _shuffle_data(self, X, y):
        """æ‰“ä¹±æ•°æ®"""
        idx = np.random.permutation(len(X))
        return X[idx], y[idx]

    def _get_batch(self, X, y, iteration):
        """è·å–æ‰¹æ¬¡æ•°æ®"""
        start = iteration * self.batch_size
        end = (iteration + 1) * self.batch_size
        return X[start:end], y[start:end]